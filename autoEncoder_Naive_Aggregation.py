# -*- coding: utf-8 -*-
"""
Created on Tue Jan 19 14:37:07 2021

@author: fergu
"""

from tensorflow.keras import backend
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.layers import Input, Dense
from tensorflow.keras.models import Model
from networkx import nx
import scipy.io as spio 
import numpy as np
import matplotlib as mpl

def colorFader(c1,c2,mix=0): #fade (linear interpolate) from color c1 (at mix=0) to c2 (mix=1)
    c1=np.array(mpl.colors.to_rgb(c1))
    c2=np.array(mpl.colors.to_rgb(c2))
    return mpl.colors.to_hex((1-mix)*c1 + mix*c2)

c1='#1f77b4' #blue
c2='green' #green



np.random.seed(0)
N = 5 #num of graphs to train on (N*n will be the number of nodes to learn embeddings of)
n = 200 #num nodes in the graph
d = 2 #num of dimensions to embed the graphs in


inputs = Input(shape=(n,))
# a layer instance is callable on a tensor, and returns a tensor
output_1 = Dense(500, activation='tanh')(inputs)
output_2 = Dense(250,activation='relu')(output_1)
output_3 = Dense(d, name = 'embeded_nodes')(output_2)
output_4 = Dense(250, activation='relu')(output_3)
output_5 = Dense(500,activation = 'tanh')(output_4)
predictions = Dense(n)(output_5)

# This creates a model that includes
# the Input layer and three Dense layers
node_model = Model(inputs=inputs, outputs=predictions)
node_model.compile(optimizer='adam',
              loss='mean_squared_error',
              metrics=['accuracy'])

embeded_nodes_model = Model(inputs=node_model.input,
                                 outputs=node_model.get_layer('embeded_nodes').output)


#Generate data for training
dataT = []
for i in range(0,N):
    #G = nx.connected_watts_strogatz_graph(n,5,0.5) #Use different ensembles to embed different graphs
    G = nx.fast_gnp_random_graph(n, 0.5)
    
    #Create the gram matrix and append info to data
    Adj = np.array(nx.adjacency_matrix(G).todense(),dtype=np.float64)   
    D = Adj.dot(np.ones(n))
    Dl = np.zeros(n)
    for j in range(0,n):
        if D[j] != 0:
            Dl[j] = D[j]**(-0.5) 
    Dl = np.diag(Dl)
    Dr = Dl
    M = ((Dl).dot(Adj)).dot(Dr)
    W, V = np.linalg.eig(M)
    gramMat = np.zeros((n,n))
    for k in range(0,n):
        V[:,k] = W[k]*V[:,k]
    for j in range(0,n):
        for k in range(0,n):
            gramMat[j,k] = np.linalg.norm(V[j,:]-V[k,:])
    for m in range(0,n):
        #Either the data is the eigenvectors of the graph given by V or the node similarities given by gramMat
        
        #dataT.append(V[j,:])
        dataT.append(gramMat[m,:])

dataT = np.array(dataT)

dataT = tf.keras.utils.normalize(dataT,axis = 1)
node_model.fit(dataT, dataT,epochs = 5,batch_size = 5)  # starts training

#Generate 20 graphs from 100 parameter values for the Erdos-Renyi ensemble.

numSets = 100 #This is the number of parameter values chosen + 1. Expect numSets - 1 different colors in the image plotted

#place to store embeded graphs
embededGraphs = np.zeros((d,(numSets)))

#store all embeded nodes
embededNodeSet = np.zeros((d,n*numSets))

#Generate a graph, embeded the nodes, aggregate the nodes, call this the embeded graph.
for p in range(0,numSets):
    
    
    data = []
    
    #If training on gnp, use gnp. If training on watts_stro embed watts_stro
    
    #G = nx.connected_watts_strogatz_graph(n,5,(p)/numSets)
    G = nx.fast_gnp_random_graph(n, (p)/numSets)
    
    #Create the gram matrix and append info to data
    Adj = np.array(nx.adjacency_matrix(G).todense(),dtype=np.float64)   
    D = Adj.dot(np.ones(n))
    Dl = np.zeros(n)
    for j in range(0,n):
        if D[j] != 0:
            Dl[j] = D[j]**(-0.5) 
    Dl = np.diag(Dl)
    Dr = Dl
    M = ((Dl).dot(Adj)).dot(Dr)
    W, V = np.linalg.eig(M)
    gramMat = np.zeros((n,n))
    for k in range(0,n):
        V[:,k] = W[k]*V[:,k]
    for j in range(0,n):
        for k in range(0,n):
            gramMat[j,k] = np.linalg.norm(V[j,:]-V[k,:])
    for m in range(0,n):
        #Either the data is the eigenvectors of the graph given by V or the node similarities given by gramMat
        
        #data.append(V[j,:])
        data.append(gramMat[m,:])

    #Embed the graph's nodes and aggregate
    embededNodes = embeded_nodes_model.predict(tf.keras.utils.normalize(data,axis = 1))
    
    embededNodeSet[:,p*n:p*n+n] = np.transpose(np.array(embededNodes))
    #Aggregate the node embeddings into a graph embedding
    embededGraph = np.sum(embededNodes,axis=0)
    embededGraphs[:,p] = embededGraph

print(embededNodeSet)

#Display the embeded graphs

#A gradient of color represents graphs generated by different parameter values. All graphs generated with the same parameter value are associated with one color.
fig, ax = plt.subplots()


for i in range(0,numSets):
    ax.scatter(embededGraphs[0][i],embededGraphs[1][i],color=colorFader(c1,c2,i/numSets))

plt.title('Embeded Graphs')

fig2, ax2 = plt.subplots()

#These variables are for tracking color changes for the plotting of embeded graphs
j = 0
counter = 0

for i in range(0,numSets*n):
    if counter < n:
        ax2.scatter(embededNodeSet[0][i],embededNodeSet[1][i],color=colorFader(c1,c2,j/numSets))
        counter = counter + 1
    else:
        j = j+1
        counter = 0
plt.title('Embeded Nodes')

ax.imshow()

